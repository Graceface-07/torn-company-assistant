import os
import re
from pathlib import Path

ROOT = Path(__file__).parent.parent
DOCS = ROOT / "docs"
LINK_PATTERN = re.compile(r"\[([^\]]+)\]\((?!http)([^)#]+)(#[^\)]*)?\)")

def find_markdown_files():
    return list(DOCS.rglob("*.md"))

def extract_links(md_path):
    links = set()
    with md_path.open("r", encoding="utf-8") as f:
        for line in f:
            for match in LINK_PATTERN.finditer(line):
                path = match.group(2).strip()
                if path.endswith(".md"):
                    links.add((md_path, path))
    return links

def normalize(path, base):
    full_path = (base / path).resolve()
    try:
        rel_path = full_path.relative_to(DOCS)
        return rel_path.as_posix()
    except ValueError:
        return None

def stub(rel_path):
    path = DOCS / rel_path
    os.makedirs(path.parent, exist_ok=True)
    title = Path(rel_path).stem.replace("_", " ").title()
    if not path.exists():
        with path.open("w", encoding="utf-8") as f:
            f.write(f"# {title}\n\n_This page was autogenerated from a broken link._\n")
        print(f"üß© Stub created: {rel_path}")

def run():
    print("üîé Scanning Markdown links...")
    all_docs = find_markdown_files()
    found = set()
    for md_file in all_docs:
        found.update(extract_links(md_file))

    existing = {
        f.relative_to(DOCS).as_posix() for f in all_docs
    }

    missing = set()
    for source_file, target in found:
        abs_target = normalize(target, source_file.parent)
        if abs_target and abs_target not in existing:
            missing.add(abs_target)

    if missing:
        print(f"\n‚ö†Ô∏è Found {len(missing)} missing linked files. Creating stubs...\n")
        for m in sorted(missing):
            stub(m)
        print("\n‚úÖ All missing files have been stubbed.")
    else:
        print("‚úÖ No broken links found.")

if __name__ == "__main__":
    run()
